<!DOCTYPE html> 
<html>
    <head>
        <title>Meowmeow</title>
        <style>
            #faceRecCanvas {
                position: absolute;
                left: 8px;
                top: 8px;
                pointer-events: none;
            }
        </style>
    </head>
    <body>
        <div id="videoElement"><video id="vid" src="video.mp4" type="video/mp4"></video></div>
        <script src="face-api.min.js"><p>didnt work</p></script>
        <script>
            var x;
            var y;
            async function run() {

                Promise.all([
                await faceapi.loadSsdMobilenetv1Model('/weights'),
                await faceapi.loadTinyFaceDetectorModel('/weights'),
                await faceapi.loadFaceLandmarkModel('/weights'),
                await faceapi.loadFaceLandmarkTinyModel('/weights'),
                await faceapi.loadFaceRecognitionModel('/weights'),
                await faceapi.loadFaceExpressionModel('/weights')
            ])
            }

            var width;
            var height;
            //const input = document.getElementById("vid");
            const input = document.getElementsByClassName("html5-main-video")[0];
            input.addEventListener("loadeddata", () => {
                run().then(res => main());
            })

            async function getCurrentFacePosition(videoElement) {
                const displaySize = { width: videoElement.videoWidth, height: videoElement.videoHeight }
                //faceapi.matchDimensions(canvas, displaySize);
                const detections = await faceapi.detectAllFaces(videoElement, 
                    new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks().withFaceExpressions();
                    // boxes will size properly for the video element
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    //console.log(resizedDetections)
                    if(resizedDetections[0] == undefined) {
                        return null;
                    }
                    return [resizedDetections[0].alignedRect.box.x + resizedDetections[0].alignedRect.box.width/2, resizedDetections[0].alignedRect.box.y + resizedDetections[0].alignedRect.box.height];
            }

            function main() {

                // Create canvas from our video element
                const canvas = faceapi.createCanvasFromMedia(input);
                canvas.id = "faceRecCanvas"
                input.setAttribute('controls', 'controls')
                document.body.append(canvas);
                // Current size of our video

                const displaySize = { width: input.videoWidth, height: input.videoHeight }
                faceapi.matchDimensions(canvas, displaySize);


                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(input, 
                    new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks().withFaceExpressions();
                    // boxes will size properly for the video element
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);

                    // canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    // faceapi.draw.drawDetections(canvas, resizedDetections);
                    // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                    // faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
                }, 10)
            }
            //$(document).ready(function() {run()})

            /* Debugging Stuff
            document.onclick = function() {
                console.log(getCurrentFacePosition())
            }
            */
  
        </script>
    </body>
</html>